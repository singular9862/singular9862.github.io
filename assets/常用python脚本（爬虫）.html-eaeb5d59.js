const n=JSON.parse(`{"key":"v-553f2cbc","path":"/Python/utils/%E5%B8%B8%E7%94%A8python%E8%84%9A%E6%9C%AC%EF%BC%88%E7%88%AC%E8%99%AB%EF%BC%89.html","title":"常用python脚本（爬虫）","lang":"zh-CN","frontmatter":{"title":"常用python脚本（爬虫）","icon":"python","order":1,"date":"2023-03-01T00:00:00.000Z","author":"singularity","category":["python"],"star":1,"isOriginal":true,"tag":["python"],"copyright":"singularity原创,未经作者同意谢绝转载","description":"简单爬取文本资料（无需登陆与反爬虫） 注：bs4的使用不赘述 假定需要爬取一本Java的在线资料，那么首先需要获取各个章节，再对各章节逐一获取内容并写入。 对于爬取到的文本的具体处理，需根据实际情况具体分析。 import requests from bs4 import BeautifulSoup def __getDocs(): url = 'https://www.xxxx/110/110742/' response = requests.get(url) if response.encoding != 'utf-8': response.encoding = 'utf-8' html = response.text soup = BeautifulSoup(html, 'html.parser') targets = soup.find(id=\\"list\\").find_all('a') for i in range(0, len(targets) - 1): urlCha = targets[i] urlCha = 'https://www.xxxx' + urlCha.get('href') __getChapter(urlCha) def __getChapter(url): response = requests.get(url) if response.encoding != 'utf-8': response.encoding = 'utf-8' html = response.text soup = BeautifulSoup(html, 'html.parser') book_name = soup.find('h1') content_texts = soup.find(id='content') with open('cText.txt', 'a', encoding='utf-8') as file: file.write(book_name.getText()+'\\\\n') lines = content_texts.text.replace(' ', 'aaaaaaaa').split('aaaaaaaa') for text in lines: file.write(text + '\\\\n') file.close() if __name__ == '__main__': __getDocs()","head":[["meta",{"property":"og:url","content":"https://singular9862.github.io/Python/utils/%E5%B8%B8%E7%94%A8python%E8%84%9A%E6%9C%AC%EF%BC%88%E7%88%AC%E8%99%AB%EF%BC%89.html"}],["meta",{"property":"og:site_name","content":"singularity"}],["meta",{"property":"og:title","content":"常用python脚本（爬虫）"}],["meta",{"property":"og:description","content":"简单爬取文本资料（无需登陆与反爬虫） 注：bs4的使用不赘述 假定需要爬取一本Java的在线资料，那么首先需要获取各个章节，再对各章节逐一获取内容并写入。 对于爬取到的文本的具体处理，需根据实际情况具体分析。 import requests from bs4 import BeautifulSoup def __getDocs(): url = 'https://www.xxxx/110/110742/' response = requests.get(url) if response.encoding != 'utf-8': response.encoding = 'utf-8' html = response.text soup = BeautifulSoup(html, 'html.parser') targets = soup.find(id=\\"list\\").find_all('a') for i in range(0, len(targets) - 1): urlCha = targets[i] urlCha = 'https://www.xxxx' + urlCha.get('href') __getChapter(urlCha) def __getChapter(url): response = requests.get(url) if response.encoding != 'utf-8': response.encoding = 'utf-8' html = response.text soup = BeautifulSoup(html, 'html.parser') book_name = soup.find('h1') content_texts = soup.find(id='content') with open('cText.txt', 'a', encoding='utf-8') as file: file.write(book_name.getText()+'\\\\n') lines = content_texts.text.replace(' ', 'aaaaaaaa').split('aaaaaaaa') for text in lines: file.write(text + '\\\\n') file.close() if __name__ == '__main__': __getDocs()"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"singularity"}],["meta",{"property":"article:tag","content":"python"}],["meta",{"property":"article:published_time","content":"2023-03-01T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"常用python脚本（爬虫）\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-03-01T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"singularity\\"}]}"]]},"headers":[],"git":{},"readingTime":{"minutes":0.78,"words":235},"filePathRelative":"Python/utils/常用python脚本（爬虫）.md","localizedDate":"2023年3月1日","excerpt":"<h4> 简单爬取文本资料（无需登陆与反爬虫）</h4>\\n<p>注：bs4的使用不赘述\\n假定需要爬取一本Java的在线资料，那么首先需要获取各个章节，再对各章节逐一获取内容并写入。\\n对于爬取到的文本的具体处理，需根据实际情况具体分析。</p>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token keyword\\">import</span> requests\\n<span class=\\"token keyword\\">from</span> bs4 <span class=\\"token keyword\\">import</span> BeautifulSoup\\n\\n\\n<span class=\\"token keyword\\">def</span> <span class=\\"token function\\">__getDocs</span><span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n    url <span class=\\"token operator\\">=</span> <span class=\\"token string\\">'https://www.xxxx/110/110742/'</span>\\n    response <span class=\\"token operator\\">=</span> requests<span class=\\"token punctuation\\">.</span>get<span class=\\"token punctuation\\">(</span>url<span class=\\"token punctuation\\">)</span>\\n    <span class=\\"token keyword\\">if</span> response<span class=\\"token punctuation\\">.</span>encoding <span class=\\"token operator\\">!=</span> <span class=\\"token string\\">'utf-8'</span><span class=\\"token punctuation\\">:</span>\\n        response<span class=\\"token punctuation\\">.</span>encoding <span class=\\"token operator\\">=</span> <span class=\\"token string\\">'utf-8'</span>\\n    html <span class=\\"token operator\\">=</span> response<span class=\\"token punctuation\\">.</span>text\\n\\n    soup <span class=\\"token operator\\">=</span> BeautifulSoup<span class=\\"token punctuation\\">(</span>html<span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'html.parser'</span><span class=\\"token punctuation\\">)</span>\\n    targets <span class=\\"token operator\\">=</span> soup<span class=\\"token punctuation\\">.</span>find<span class=\\"token punctuation\\">(</span><span class=\\"token builtin\\">id</span><span class=\\"token operator\\">=</span><span class=\\"token string\\">\\"list\\"</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">.</span>find_all<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'a'</span><span class=\\"token punctuation\\">)</span>\\n    <span class=\\"token keyword\\">for</span> i <span class=\\"token keyword\\">in</span> <span class=\\"token builtin\\">range</span><span class=\\"token punctuation\\">(</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">len</span><span class=\\"token punctuation\\">(</span>targets<span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">-</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n        urlCha <span class=\\"token operator\\">=</span> targets<span class=\\"token punctuation\\">[</span>i<span class=\\"token punctuation\\">]</span>\\n        urlCha <span class=\\"token operator\\">=</span> <span class=\\"token string\\">'https://www.xxxx'</span> <span class=\\"token operator\\">+</span> urlCha<span class=\\"token punctuation\\">.</span>get<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'href'</span><span class=\\"token punctuation\\">)</span>\\n        __getChapter<span class=\\"token punctuation\\">(</span>urlCha<span class=\\"token punctuation\\">)</span>\\n\\n\\n<span class=\\"token keyword\\">def</span> <span class=\\"token function\\">__getChapter</span><span class=\\"token punctuation\\">(</span>url<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n    response <span class=\\"token operator\\">=</span> requests<span class=\\"token punctuation\\">.</span>get<span class=\\"token punctuation\\">(</span>url<span class=\\"token punctuation\\">)</span>\\n    <span class=\\"token keyword\\">if</span> response<span class=\\"token punctuation\\">.</span>encoding <span class=\\"token operator\\">!=</span> <span class=\\"token string\\">'utf-8'</span><span class=\\"token punctuation\\">:</span>\\n        response<span class=\\"token punctuation\\">.</span>encoding <span class=\\"token operator\\">=</span> <span class=\\"token string\\">'utf-8'</span>\\n    html <span class=\\"token operator\\">=</span> response<span class=\\"token punctuation\\">.</span>text\\n\\n    soup <span class=\\"token operator\\">=</span> BeautifulSoup<span class=\\"token punctuation\\">(</span>html<span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'html.parser'</span><span class=\\"token punctuation\\">)</span>\\n    book_name <span class=\\"token operator\\">=</span> soup<span class=\\"token punctuation\\">.</span>find<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'h1'</span><span class=\\"token punctuation\\">)</span>\\n    content_texts <span class=\\"token operator\\">=</span> soup<span class=\\"token punctuation\\">.</span>find<span class=\\"token punctuation\\">(</span><span class=\\"token builtin\\">id</span><span class=\\"token operator\\">=</span><span class=\\"token string\\">'content'</span><span class=\\"token punctuation\\">)</span>\\n\\n    <span class=\\"token keyword\\">with</span> <span class=\\"token builtin\\">open</span><span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'cText.txt'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'a'</span><span class=\\"token punctuation\\">,</span> encoding<span class=\\"token operator\\">=</span><span class=\\"token string\\">'utf-8'</span><span class=\\"token punctuation\\">)</span> <span class=\\"token keyword\\">as</span> <span class=\\"token builtin\\">file</span><span class=\\"token punctuation\\">:</span>\\n        <span class=\\"token builtin\\">file</span><span class=\\"token punctuation\\">.</span>write<span class=\\"token punctuation\\">(</span>book_name<span class=\\"token punctuation\\">.</span>getText<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span><span class=\\"token operator\\">+</span><span class=\\"token string\\">'\\\\n'</span><span class=\\"token punctuation\\">)</span>\\n        lines <span class=\\"token operator\\">=</span> content_texts<span class=\\"token punctuation\\">.</span>text<span class=\\"token punctuation\\">.</span>replace<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'    '</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'aaaaaaaa'</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">.</span>split<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'aaaaaaaa'</span><span class=\\"token punctuation\\">)</span>\\n        <span class=\\"token keyword\\">for</span> text <span class=\\"token keyword\\">in</span> lines<span class=\\"token punctuation\\">:</span>\\n            <span class=\\"token builtin\\">file</span><span class=\\"token punctuation\\">.</span>write<span class=\\"token punctuation\\">(</span>text <span class=\\"token operator\\">+</span> <span class=\\"token string\\">'\\\\n'</span><span class=\\"token punctuation\\">)</span>\\n    <span class=\\"token builtin\\">file</span><span class=\\"token punctuation\\">.</span>close<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n\\n\\n<span class=\\"token keyword\\">if</span> __name__ <span class=\\"token operator\\">==</span> <span class=\\"token string\\">'__main__'</span><span class=\\"token punctuation\\">:</span>\\n    __getDocs<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}`);export{n as data};
